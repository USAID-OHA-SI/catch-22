---
project: fo_organization
layout: "post"
title: "Intro to Visualization - 0 Script Structure"
date: "2023-06-26"
author: "Prasann Ranade"
categories: [viz, tools]
tags: [r]
output: word_document
---

# Intro to Visualization - 0 The Structure of a Script

## Agenda:

[ Guiding purpose of this FO visualization write-up ]
[ Toward a more modular approach for writing scripts ]
[ 1. Documentation: what's standard boilerplate? ]
[ 2. Dependencies: what packages should I load? ]
[ 3. Global Variables: how do I store metadata? ]
[ 4. Importing Data: how do I find my dataset? ]
[ 5. Key topics: common functions, variables, and time periods ]
[ 6. Demos with specific plots: check out the other scripts ]

# Guiding purpose of this FO visualization write-up

As one of the key tools in our data analysis and visualization repertoire, the programming language R is well-used by the SI team and allows us to produce beautiful and functional visuals with efficient, replicable scripts. However, these scripts can easily become complicated with too-specific comments and unique datasets that may make them hard to reuse or decipher by new hires. In this short organizational manual, we will attempt to demystify these scripts, reorganize them into a more modular structure, and improve their accessibility for all users.

# Toward a more modular approach for writing scripts

This document employs the R Markdown document style to provide greater context to and display the outputs of the code in each chunk. Code chunks in all sections are intended to be copied in a pick-and-choose, modular way to provide a template when creating your scripts, and this approach should be especially helpful in the later plotting demo scripts to easily identify key lines of code for each type of plot. When adapting this code, you can select the R code within the tick marks (\`\`\`) and alter variable names and functions to fit your needs. Remember to also change or provide new comments to clarify any choices taken, instead of using them for purely descriptive purpose as in the code chunks in this manual.

# 1. Documentation: what's standard boilerplate?

Let's begin with some boilerplate: the header section. As this text differs slightly between regular R scripts and R markdown documents, the code used for R scripts has been provided below for ease of reference. Note that this section is usually commented out in R scripts. An important element missing in this header is the reference ID for each script to help match up a script and its visual; this ID is usually a random string of numbers instantiated in the final visualization section of a script and included in the visual's caption.

```{r}
# PROJECT:  FO_organization
# AUTHOR:  F. Lastname | USAID
# PURPOSE:  for this script/visual
# LICENSE:  MIT
# DATE:     2023-05-26
# UPDATED:  2023-05-27
# NOTE:  any reference scripts
```

# 2. Dependencies: what packages should I load?

Before using R functions in your code to read in data and create visuals, the packages those functions belong to need to be loaded. You can think of these packages or libraries as three groups: the behind-the-scenes of R ("tidyverse", "dplyr"), the behind-the-scenes of SI ("gagglr" [which loads "glitr", "glamr", and "gophr"] and "glue"), and the behind-the-scenes of plotting/labeling ("tidytext", "ggtext", "patchwork", "scales"). Calling the name of each library at the start of your code will instantiate the package, and you can also install new packages to your environment from the CRAN repository, R's central repository of packages. Since most SI packages are not on that repository, you will need to download them using devtools.
 
Key libraries:
- behind-the-scenes of R ("tidyverse", "dplyr")
- behind-the-scenes of SI ("gagglr" [which loads "glitr", "glamr", and "gophr"] and "glue")
- behind-the-scenes of plotting/labeling ("tidytext", "ggtext", "patchwork", "scales")

```{r eval=FALSE}
# DOCUMENTATION ----------------------------------------------------------------
# common libraries for most scripts:
library(tidyverse)
library(glitr)
library(glamr)
library(gophr)
library(extrafont)
library(scales)
library(tidytext)
library(patchwork)
library(ggtext)
library(glue)

# to install common R packages from CRAN
install.packages("tidyverse") 

# to install SI-specific packages, requires the "devtools" package to be installed
remotes::install_github("USAID-OHA-SI/glitr") #
```

# 3. Global Variables: how do I store metadata?

The SI team utilizes a standard set of R functions and directory management workflow that is better described in the article below. In particular, the "si_setup", "set_paths", and "si_path" function all help standardize where your data is stored and imported from on your local machine. In this way, instead of setting a new working directory every time and searching up the specific name of your dataset, you can easily pull your dataset from its last known location and with only a few identifying terms, as shown in the next section. <https://usaid-oha-si.github.io/glamr/articles/project-workflow.html>

# 4. Importing Data: how do I find my dataset?

Once you have the SI workflow set up from the link above, you can easily import MSD files or other documents using the "return_latest" SI function to read in the latest file stored in the Data folder in your directory structure. For example, when creating the "df" dataframe below, the training dataset used for these markdown files is being imported with just a small part of the filename. The "df_arch" lines of code similarly import a dataset that matches the "OU_IM_FY15" part in a filename and is a more useful chunk to copy when importing your own datasets.

Key functions: 
- si_path: set up using the Project Workflow link above
- return_latest: fetch the last used data file using this SI function
- read_psd: used to efficiently read in large MSD files

```{r eval=FALSE}
# IMPORT -----------------------------------------------------------------------
# import a current MSD with the right fiscal year(s)
df <- si_path() %>% 
  return_latest("PSNU_IM_FY48-49") %>% 
  read_msd()  

# import an archived MSD the same way
df_arch <- si_path() %>% 
  return_latest("OU_IM_FY15") %>% 
  read_msd()
```
# 5. Key topics: common functions, variables, and time periods 

After importing your dataset, it may be necessary to perform some pre-processing steps like filtering down to specific columns before beginning with data munging. 

Key functions:
- filter: filters to a set of values in the columns of a dataframe
- select: chooses which columns to copy over to a new dataset
- group_by: organize a dataframe by columns in a progressive order
- summarize: perform an arithmetic function across values in a column (in this case, a sum)
- mutate: add new columns to a dataframe or modify existing ones
- ungroup: prevent future data errors by ungrouping the dataframe after performing any filtering

```{r eval=FALSE}
df_tx <- df %>% 
  # filter to these values
  filter(indicator %in% c("TX_CURR", "TX_NEW", "HTS_TST_POS"),
         disaggregate %in% "Total Numerator") %>% 
  
  # choose which columns to copy over to your new dataset
  select(planet,fiscal_year, indicator, cumulative, targets) %>% 
  
  # choose the order to group rows by (ex. by planet first then indicator)
  group_by(planet,indicator, fiscal_year) %>% 
  
  # sum up values for each indicator across all regions
  summarize(across(everything(), sum, na.rm = TRUE)) %>% 
  #summarize(across(targets, sum, na.rm = TRUE)) %>% 
  
  # rename the fiscal_year column
  rename(period = fiscal_year) %>%
  mutate(period = str_replace(period, "20", "FY")) %>%
  
  # ungroup columns after doing any data manipulation
  ungroup()
```

Additionally, just as most MSDs or other datasets use a consistent set of columns and values, it is important to keep variable names consistent when writing scripts. For example, variables used for dataframes when importing and using data will include "df", "df_arch", "df_tx", "df_prep", or "df_viz" as shown in the code chunk above. Remember to create a new dataframe when performing munging or visualization instead of modifying the original dataset, to make it easier to see changes across dataframes.

Lastly, as a note on time periods, the fiscal_year column used in MSDs may need to be renamed or modified to a period column when working with semi-annual or annual indicators like KP_PREV or PReP_CT, as those cumulative indicators will differ from snapshot indicators like TX_CURR in their cumulative values.

# 6. Demos with specific plots: check out the other scripts

As mentioned earlier, these set of visualization scripts will include demo scripts to create particular kinds of plots. Specifically, the remaining scripts will each aim to pull a prepped MSD dataframe into ggplot and make the following kinds of charts: 1. a bar chart showing results across time (or results/targets across time with stacked bars) 2. faceted plots by top countries 3. plots broken out by age/sex standardized disaggregates Those scripts will be written in a similar modular manner, so pick and choose sections from this document and other documents to put together a cohesive script!
